{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a282fa94",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jiaoyilin/anaconda3/envs/test/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "from torch.utils.data import DataLoader\n",
    "import pynvml\n",
    "import psutil\n",
    "import string\n",
    "\n",
    "def remove_non_printable(s):\n",
    "    return ''.join(c for c in s if c not in string.printable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691aa3de",
   "metadata": {},
   "source": [
    "#查看内存的函数\n",
    "def get_avaliable_memory(device):\n",
    "    if device==torch.device('cuda:0'):\n",
    "        pynvml.nvmlInit()\n",
    "        handle = pynvml.nvmlDeviceGetHandleByIndex(0)        # 0表示第一块显卡\n",
    "        meminfo = pynvml.nvmlDeviceGetMemoryInfo(handle)\n",
    "        ava_mem=round(meminfo.free/1024**2)\n",
    "        print('current available video memory is' +' : '+ str(round(meminfo.free/1024**2)) +' MIB')\n",
    "\n",
    "    elif device==torch.device('cpu'):\n",
    "        mem = psutil.virtual_memory()\n",
    "        print('current available memory is' +' : '+ str(round(mem.used/1024**2)) +' MIB')\n",
    "        ava_mem=round(mem.used/1024**2)\n",
    "\n",
    "    return ava_mem\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bfe6a624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MD换成97终于能做了，如果CPU和内存都好一些，可以尝试用320M的\n",
    "def data_dealing(file_path):\n",
    "    df = pd.read_excel(file_path)\n",
    "    tokenizer=AutoTokenizer.from_pretrained('IDEA-CCNL/Erlangshen-DeBERTa-v2-97M-Chinese')    #这个写作的话需要引用别人论文\n",
    "\n",
    "    features=[]\n",
    "    for i in range(len(df)):\n",
    "        text=df['回复内容'][i]\n",
    "        new_text=remove_non_printable(text) #去除大部分文本占位符\n",
    "        input_id = tokenizer.encode(new_text)\n",
    "        if len(input_id)>1500:\n",
    "            print(i,text,df['Unnamed: 0'][i])\n",
    "            continue\n",
    "        #print(i,df['政府回复类型'][i])     #测试时候用\n",
    "        answer = df['政府回复类型'][i]\n",
    "        if answer=='解决':                  #知悉是0，解决是1，解释是2\n",
    "            tag=1\n",
    "        if answer=='解释':\n",
    "            tag=2\n",
    "        if answer=='知悉':\n",
    "            tag=0\n",
    "        feature = {'input_id':input_id,'tags':tag,'input_len':len(input_id)}   #记录下文本内容吧，别很多超过510的\n",
    "        features.append(feature)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cdf1b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MD换成97终于能做了，如果CPU和内存都好一些，可以尝试用320M的\n",
    "def data_deal_liuyan(file_path):\n",
    "    df = pd.read_excel(file_path)\n",
    "    tokenizer=AutoTokenizer.from_pretrained('IDEA-CCNL/Erlangshen-DeBERTa-v2-320M-Chinese')    #这个写作的话需要引用别人论文\n",
    "\n",
    "    features=[]\n",
    "    for i in range(len(df)):\n",
    "        text=df['留言文本'][i]\n",
    "        #print(i,df['政府回复类型'][i])     #测试时候用\n",
    "        new_text=remove_non_printable(text)\n",
    "        input_id = tokenizer.encode(new_text)\n",
    "        \n",
    "        answer = df['投诉类型'][i]\n",
    "        if answer==0:                  #抑制是0，建设是1，中立是2\n",
    "            tag=0\n",
    "        if answer==1:\n",
    "            tag=1\n",
    "        if answer=='中立':\n",
    "            tag=2 \n",
    "        feature = {'input_id':input_id,'tags':tag,'input_len':len(input_id)}   #记录下文本内容吧，别很多超过510的\n",
    "        features.append(feature)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57acc03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#这里是因为要用已有的模型来标记数据，所以新设置一个\n",
    "def test_collate_fn(batch):\n",
    "    max_len = max([len(f[\"input_id\"]) for f in batch])\n",
    "    input_id = [f['input_id'] + [0] * (max_len - len(f['input_id'])) for f in batch]\n",
    "    input_mask = [[1] * len(f['input_id']) + [0] * (max_len - len(f['input_id'])) for f in batch]\n",
    "        \n",
    "    input_id = torch.tensor(input_id)\n",
    "    input_mask = torch.tensor(input_mask)\n",
    "    \n",
    "    output = (input_id, input_mask)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b2993861",
   "metadata": {},
   "outputs": [],
   "source": [
    "#这里换个思路，每跑一次就存一次！\n",
    "def add_data(file_path,model,file_name,device):\n",
    "    df = pd.read_excel(file_path)       #光这一步就要占用很多内存\n",
    "    tokenizer=AutoTokenizer.from_pretrained('IDEA-CCNL/Erlangshen-DeBERTa-v2-320M-Chinese')    #这个写作的话需要引用别人论文\n",
    "        #先获得数据\n",
    "    features=[]\n",
    "    for i in range(len(df)):\n",
    "        text=df['leaveContent'][i]\n",
    "        if pd.isna(text) or type(text)==int:\n",
    "            continue                          #如果是nan或者文本是数字就跳过\n",
    "        new_text=remove_non_printable(text)   #去除大部分转义字符\n",
    "        if len(new_text)>2000:                #有7000多字的回复你敢信？设置3000的时候还是会爆内存，就干脆设置2000吧\n",
    "            continue\n",
    "        input_id = tokenizer.encode(new_text)  \n",
    "        feature = {'input_id':input_id,'index':i,}  \n",
    "        features.append(feature)              \n",
    "    print('数据总量:',len(df),'feature数量:',len(features))\n",
    "    \n",
    "    preds=[]\n",
    "    dataloader =  DataLoader(features, batch_size=2, shuffle=False, collate_fn=test_collate_fn, drop_last=False)   \n",
    "    for step, batch in enumerate(dataloader):\n",
    "        model.eval()\n",
    "        inputs = {'input_id': batch[0].to(device),\n",
    "                  'input_mask': batch[1].to(device),\n",
    "              }\n",
    "        with torch.no_grad():\n",
    "            output = model(**inputs)     \n",
    "            preds.extend(output[0].cpu())       \n",
    "            torch.cuda.empty_cache()           #加上这一步主动释放内存就ok了\n",
    "        if step%5000==0:\n",
    "            print(\"当前运行数据:\",step*2) \n",
    "            \n",
    "    result=[]                    #知悉是0，解决是1，解释是2\n",
    "    for n in range(len(preds)):\n",
    "        y_pred=preds[n].argmax(dim=-1)\n",
    "        if y_pred==0:\n",
    "            result.append('抑制')\n",
    "        if y_pred==1:\n",
    "            result.append('建设')\n",
    "        if y_pred==2:\n",
    "            result.append('中立')\n",
    "        \n",
    "    #这里注意一下，这个df的数据类型，需要直接放入长度相同的list才能创建，比较麻烦\n",
    "    new_result=[]\n",
    "    index=0       \n",
    "    for i in range(len(df)):\n",
    "        if index==len(features) or i!=features[index]['index']:\n",
    "            new_result.append('留言内容过长')\n",
    "        else:\n",
    "            new_result.append(result[index])\n",
    "            index += 1\n",
    "    df['留言类型（机器）']=new_result\n",
    "    df.to_excel('final_result/'+file_name,sheet_name='sheet1',index=False)\n",
    "    \n",
    "    return new_result,preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09392209",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#11到18这几年的留言回复花了6个h，19到22得5个小时，夸张！\n",
    "#然后这里还是用liuyan_result的数据做结果，只不过最后读数据读新result的数据就行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af362ea8",
   "metadata": {},
   "source": [
    "%%time\n",
    "x=list(range(2021,2023))   #19年的跑完了\n",
    "for num in x:\n",
    "    file_path='final_result/'+str(num)+'.xlsx'\n",
    "    file_name=str(num)+'_new.xlsx'\n",
    "    print(file_path,file_name)\n",
    "    y=add_data(file_path,my_model,file_name,device)\n",
    "#然后留言是19到22都没做，直接从final_result里的19到22做就行"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eca5612",
   "metadata": {},
   "source": [
    "file_path='留言板/2019上.xlsx'\n",
    "df = pd.read_excel(file_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46fef660",
   "metadata": {},
   "source": [
    "#先看下数据能否读的进去\n",
    "df = pd.read_excel('data.xlsx')\n",
    "df.head()\n",
    "\n",
    "#先测试下分词效果\n",
    "tokenizer=AutoTokenizer.from_pretrained('IDEA-CCNL/Erlangshen-DeBERTa-v2-710M-Chinese')    #这个写作的话需要引用别人论文\n",
    "test_text=df['回复内容'][2]\n",
    "#print(type(test_text))\n",
    "#print(test_text)\n",
    "x=tokenizer.encode(test_text)\n",
    "len(x)\n",
    "#从结果来看，就是单纯的把字分开了，不是纯粹的分词，这个不知道会不会对性能有影响，先做着看\n",
    "#x=tokenizer.convert_tokens_to_ids(tokenizer.tokenize(test_text))\n",
    "#记得加CLS和SEP，测试通过"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:test] *",
   "language": "python",
   "name": "conda-env-test-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
